{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ASL Recognition with Pose estimation","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport os\nimport string\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch\nimport torchvision.transforms as transforms\nimport pickle\nimport random\nimport seaborn as sn\nimport pandas as pd\nimport copy\nfrom sklearn.metrics import confusion_matrix\nimport cv2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-16T21:58:44.373933Z","iopub.execute_input":"2022-11-16T21:58:44.374398Z","iopub.status.idle":"2022-11-16T21:58:47.096379Z","shell.execute_reply.started":"2022-11-16T21:58:44.374285Z","shell.execute_reply":"2022-11-16T21:58:47.095397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import MediaPipe Hands API","metadata":{}},{"cell_type":"code","source":"!python -V\n!python -m pip install --upgrade pip\n\n!pip install mediapipe\n\nimport mediapipe as mp\nmp_drawing = mp.solutions.drawing_utils\nmp_drawing_styles = mp.solutions.drawing_styles\nmp_hands = mp.solutions.hands","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:58:47.098353Z","iopub.execute_input":"2022-11-16T21:58:47.099186Z","iopub.status.idle":"2022-11-16T21:59:23.823639Z","shell.execute_reply.started":"2022-11-16T21:58:47.099148Z","shell.execute_reply":"2022-11-16T21:59:23.822554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define classes","metadata":{}},{"cell_type":"code","source":"classes = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n           'W', 'X', 'Y', 'Z', 'del', 'space')\n\nclasses_NULL = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n           'W', 'X', 'Y', 'Z', 'del', 'space', 'null')","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:23.879765Z","iopub.execute_input":"2022-11-16T21:59:23.880127Z","iopub.status.idle":"2022-11-16T21:59:23.893033Z","shell.execute_reply.started":"2022-11-16T21:59:23.880089Z","shell.execute_reply":"2022-11-16T21:59:23.892104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Helper functions","metadata":{}},{"cell_type":"code","source":"# Normalizes hand keypoints\ndef transformPoints(handcoords):\n    x_coords = []\n    y_coords = []\n    for idx, coord in enumerate(handcoords):\n        if idx % 2: y_coords.append(coord)\n        else: x_coords.append(coord)\n    x_min = min(x_coords)\n    y_min = min(y_coords)\n    x_max = max(x_coords)\n    y_max = max(y_coords)\n    transformed = []\n    for idx, coord in enumerate(handcoords):\n        if idx % 2:\n            tf_coord = (coord - y_min) / (y_max - y_min)\n        else:\n            tf_coord = (coord - x_min) / (x_max - x_min)\n        transformed.append(tf_coord)\n    return transformed","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:23.826407Z","iopub.execute_input":"2022-11-16T21:59:23.827142Z","iopub.status.idle":"2022-11-16T21:59:23.836077Z","shell.execute_reply.started":"2022-11-16T21:59:23.827100Z","shell.execute_reply":"2022-11-16T21:59:23.834535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Runs MediaPipe Hands on given image file\ndef dataFromImage(file):\n    with mp_hands.Hands(\n        static_image_mode=True,\n        max_num_hands=2,\n        min_detection_confidence=0.5) as hands:\n        image = cv2.imread(file)\n        # Convert the BGR image to RGB before processing.\n        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n        if not results.multi_hand_landmarks:\n            return torch.tensor([0]), False\n        righthand_idx = 0\n        is_righthand = False\n        for i, handedness in enumerate(results.multi_handedness):\n            if handedness.classification[0].label == 'Left': #since it is mirrored by default\n                righthand_idx = i\n                is_righthand = True\n                break\n        handcoords = []\n        hand_landmarks = results.multi_hand_landmarks[righthand_idx]\n        for point in hand_landmarks.landmark:\n            handcoords.append(point.x)\n            handcoords.append(point.y)\n        handcoords = transformPoints(handcoords)\n        coords_tensor = torch.Tensor(handcoords)\n    return coords_tensor, True","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:23.838885Z","iopub.execute_input":"2022-11-16T21:59:23.839263Z","iopub.status.idle":"2022-11-16T21:59:23.849576Z","shell.execute_reply.started":"2022-11-16T21:59:23.839228Z","shell.execute_reply":"2022-11-16T21:59:23.848674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loads the images from the folder structure and runs pose estimation\ndef loadFromFolders(rootpath, classes):\n    dataset = []\n    for label, cl in enumerate(classes):\n        path = rootpath + cl\n        if os.path.exists(path):\n            for idx, filename in enumerate(os.listdir(path)):\n                f = os.path.join(path, filename)\n                # checking if it is a file\n                if os.path.isfile(f):\n                    coords, success = dataFromImage(f)\n                    if success:\n                        element = (coords, label)\n                        dataset.append(element)\n                        # Print progress\n                        if idx%100 == 0: print(classes[label], \":\", idx, \" ready\")\n            print(\"Class\", cl, \"is ready\")\n        else: print(\"Class\", cl, \"is not in current dir\")\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:23.850909Z","iopub.execute_input":"2022-11-16T21:59:23.851398Z","iopub.status.idle":"2022-11-16T21:59:23.865206Z","shell.execute_reply.started":"2022-11-16T21:59:23.851362Z","shell.execute_reply":"2022-11-16T21:59:23.864163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot and save train statistics\ndef saveTrainPlots(best_result, statistics, name):\n    train_loss = statistics[0]\n    valid_loss = statistics[1]\n    accuracy = statistics[2]\n    validation_num = statistics[3]\n    textoffset = int(len(validation_num)*0.0375)\n    text = 'Val.: '+str(best_result[0])+' Loss.: '+str(round(best_result[1], 3))\n    plt.figure(dpi=500)\n    plt.xlabel('Validation number')\n    plt.ylabel('Loss')\n    plt.plot(validation_num, train_loss, 'r', label='Train loss')\n    plt.plot(validation_num, valid_loss, 'b', label='Validation loss')\n    plt.plot(best_result[0], best_result[1], 'ko')\n    plt.text(best_result[0]+textoffset, best_result[1], text, backgroundcolor = (0.9, 0.9, 0.9))\n    plt.legend()\n    plt.savefig('./' + name + '_losses.png')\n\n    plt.figure(dpi=500)\n    plt.xlabel('Validation number')\n    plt.ylabel('Accuracy')\n    plt.plot(validation_num, accuracy, 'g')\n    plt.savefig('./' + name + '_accuracy.png')","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:23.866652Z","iopub.execute_input":"2022-11-16T21:59:23.867154Z","iopub.status.idle":"2022-11-16T21:59:23.878456Z","shell.execute_reply.started":"2022-11-16T21:59:23.867116Z","shell.execute_reply":"2022-11-16T21:59:23.877582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot and save test confusion matrix\ndef saveConfMtx(truth_array, pred_array, modelName, NULL):\n    if NULL: cl = classes_NULL\n    else: cl = classes\n    outputconfmtx = './'+modelName+'conf_mtx.png'\n    cf_matrix = confusion_matrix(truth_array, pred_array)\n    df_cm = pd.DataFrame(cf_matrix, index = [i for i in cl],\n                        columns = [i for i in cl])\n    plt.figure(figsize = (12,7))\n    sn.heatmap(df_cm, annot=True, fmt=\"1.0f\")\n    plt.savefig(outputconfmtx)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:29.814770Z","iopub.execute_input":"2022-11-16T21:59:29.815505Z","iopub.status.idle":"2022-11-16T21:59:29.825453Z","shell.execute_reply.started":"2022-11-16T21:59:29.815470Z","shell.execute_reply":"2022-11-16T21:59:29.824183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print test accuracy\ndef printAccuracy(truth_array, pred_array):\n    correct = 0\n    total = len(truth_array)\n    for i, truth in enumerate(truth_array):\n        if truth == pred_array[i]: correct += 1\n    print(f'Accuracy of the network on the test images: {100 * correct // total} %')","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:29.799943Z","iopub.execute_input":"2022-11-16T21:59:29.800629Z","iopub.status.idle":"2022-11-16T21:59:29.813057Z","shell.execute_reply.started":"2022-11-16T21:59:29.800594Z","shell.execute_reply":"2022-11-16T21:59:29.812135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import or generate the dataset","metadata":{}},{"cell_type":"code","source":"generatedata = False # Needs to be true for running MediaPipe Hands\n\n# If keypoint coordinate tensors are not extracted yet\nif generatedata:\n    dataset_letters_path = \"/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train/\"\n    dataset_null_path = \"/kaggle/input/nothing/\"\n\n    dataset_letters = loadFromFolders(dataset_letters_path, classes)\n    dataset_null = loadFromFolders(dataset_null_path, classes)\n\n    file = open('dataset_letters-null.dat', 'wb')\n    pickle.dump(dataset_letters, file)\n    pickle.dump(dataset_null, file)\n    file.close()\n    \n# Load keypoint dataset from file if already extracted and saved\nelse:\n    file = open('/kaggle/input/datatensors/dataset_letters-null.dat', 'rb')\n    dataset_letters = pickle.load(file)\n    dataset_null = pickle.load(file)\n    file.close()","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:23.894463Z","iopub.execute_input":"2022-11-16T21:59:23.895063Z","iopub.status.idle":"2022-11-16T21:59:29.605653Z","shell.execute_reply.started":"2022-11-16T21:59:23.895027Z","shell.execute_reply":"2022-11-16T21:59:29.604600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print number of elements for each class\nclassrep = [0]*len(classes_NULL)\nfor coords, label in (dataset_letters + dataset_null):\n    classrep[label] = classrep[label] + 1\n    \nfor label, num in enumerate(classrep):\n    print(classes_NULL[label] + ': ' + str(num))","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:29.607158Z","iopub.execute_input":"2022-11-16T21:59:29.607563Z","iopub.status.idle":"2022-11-16T21:59:29.638471Z","shell.execute_reply.started":"2022-11-16T21:59:29.607526Z","shell.execute_reply":"2022-11-16T21:59:29.637390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating models and training them\n\nDefine models","metadata":{}},{"cell_type":"code","source":"class SmallNet(nn.Module):\n    def __init__(self, numofclasses):\n        super().__init__()\n        self.fc1 = nn.Linear(42, 400)\n        self.fc2 = nn.Linear(400, 400)\n        self.fc3 = nn.Linear(400, 100)\n        self.fc4 = nn.Linear(100, numofclasses)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x\n\nclass LargeNet(nn.Module):\n    def __init__(self, numofclasses):\n        super().__init__()\n        self.fc1 = nn.Linear(42, 500)\n        self.fc2 = nn.Linear(500, 1000)\n        self.fc3 = nn.Linear(1000, 1000)\n        self.fc4 = nn.Linear(1000, 1000)\n        self.fc5 = nn.Linear(1000, 500)\n        self.fc6 = nn.Linear(500, numofclasses)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = F.relu(self.fc4(x))\n        x = F.relu(self.fc5(x))\n        x = self.fc6(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:29.643032Z","iopub.execute_input":"2022-11-16T21:59:29.643340Z","iopub.status.idle":"2022-11-16T21:59:29.654526Z","shell.execute_reply.started":"2022-11-16T21:59:29.643302Z","shell.execute_reply":"2022-11-16T21:59:29.653388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Set training parameters","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:29.656244Z","iopub.execute_input":"2022-11-16T21:59:29.656872Z","iopub.status.idle":"2022-11-16T21:59:29.738188Z","shell.execute_reply.started":"2022-11-16T21:59:29.656835Z","shell.execute_reply":"2022-11-16T21:59:29.737186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare the dataset and the  for training","metadata":{}},{"cell_type":"code","source":"def prepareDataAndModel(modelsize, NULL):\n    #PREPARE MODEL\n    if NULL: numofclasses = len(classes_NULL)\n    else:  numofclasses = len(classes)\n    if modelsize == 'small':\n        net = SmallNet(numofclasses)\n    elif modelsize == 'large':\n        net = LargeNet(numofclasses)\n    optimizer = optim.Adam(net.parameters(), lr=0.001)\n    model = net.to(device)\n    #PREPARE DATASET\n    batch_size = 16\n    if NULL:\n        dataset = dataset_letters + dataset_null\n        modelName = modelsize +'_NULL'\n    else:\n        dataset = dataset_letters\n        modelName = modelsize\n    #split train-valid-test 80-10-10\n    trainset, testset = random_split(dataset, [int(0.8 * len(dataset)),\n                        len(dataset) - int(0.8 * len(dataset))], generator=torch.Generator().manual_seed(42))\n    testset, validationset = random_split(testset, [int(0.5 * len(testset)),\n                        len(testset) - int(0.5 * len(testset))], generator=torch.Generator().manual_seed(42))\n    \n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n    validationloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n    testloader = torch.utils.data.DataLoader(validationset, batch_size=batch_size, shuffle=True)\n    return model, modelName, optimizer, trainloader, validationloader, testloader","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:29.739990Z","iopub.execute_input":"2022-11-16T21:59:29.740675Z","iopub.status.idle":"2022-11-16T21:59:29.751382Z","shell.execute_reply.started":"2022-11-16T21:59:29.740638Z","shell.execute_reply":"2022-11-16T21:59:29.750419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Functions for training","metadata":{}},{"cell_type":"code","source":"def validation(model, device, valid_loader, loss_function):\n    # Settings\n    model.eval()\n    loss_total = 0\n    correct = 0\n    total = 0\n\n    # Test validation data\n    with torch.no_grad():\n        for data in valid_loader:\n            inputs, labels = data[0].to(device), data[1].to(device)\n            # calculate outputs by running images through the network\n            outputs = model(inputs)\n            \n            #loss\n            loss = loss_function(outputs, labels)\n            loss_total += loss.item()\n            \n            #accuracy\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    return loss_total / len(valid_loader), 100 * correct // total","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:29.754830Z","iopub.execute_input":"2022-11-16T21:59:29.755576Z","iopub.status.idle":"2022-11-16T21:59:29.766712Z","shell.execute_reply.started":"2022-11-16T21:59:29.755540Z","shell.execute_reply":"2022-11-16T21:59:29.765736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, optimizer, trainloader, validationloader):\n    train_loss = []\n    valid_loss = []\n    accuracy = []\n    validation_num = []\n    min_loss = 1000\n    val_cntr = 0\n    for epoch in range(10):  # Loop over the dataset multiple times\n        model.train()\n        running_loss = 0.0\n        for i, data in enumerate(trainloader, 0):\n            # Get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data[0].to(device), data[1].to(device)\n\n            # Zero the parameter gradients\n            optimizer.zero_grad()\n\n            # Forward + backward + optimize\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n            # Validate and save statistics after every 50 batches\n            if i % 50 == 49:\n                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss:.3f}')\n                val_cntr = val_cntr + 1\n                the_current_loss, the_current_acc = validation(model, device, validationloader, criterion)\n                train_loss.append(running_loss)\n                valid_loss.append(the_current_loss)\n                accuracy.append(the_current_acc)\n                validation_num.append(val_cntr)\n                print(\"validation loss =\", str(the_current_loss))\n                # If the current model is the best yet\n                if the_current_loss < min_loss:\n                    min_loss = the_current_loss\n                    best_model_wts = copy.deepcopy(model.state_dict())\n                    print(\"NEW MIN LOSS =\", str(min_loss))\n                    best_result = (val_cntr, min_loss)\n            \n            running_loss = 0.0\n            \n    print('Finished Training')\n    # Load the best model\n    model.load_state_dict(best_model_wts)\n    statistics = (train_loss, valid_loss, accuracy, validation_num)\n    return model, best_result, statistics","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:29.769833Z","iopub.execute_input":"2022-11-16T21:59:29.770537Z","iopub.status.idle":"2022-11-16T21:59:29.782905Z","shell.execute_reply.started":"2022-11-16T21:59:29.770503Z","shell.execute_reply":"2022-11-16T21:59:29.781868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(model, testloader):\n    truth_array = []\n    pred_array = []\n    model.eval()\n    # Since we're not training, we don't need to calculate the gradients for our outputs\n    with torch.no_grad():\n        for data in testloader:\n            features, labels = data[0].to(device), data[1].to(device)\n            # Calculate outputs by running the data through the network\n            outputs = model(features)\n            soft_outputs = torch.nn.functional.softmax(outputs, dim=1)\n            # The class with the highest energy is what we choose as prediction\n            confidence, predicted = torch.max(soft_outputs.data, 1)\n            truth_array += labels.tolist()\n            pred_array += predicted.tolist()\n    return truth_array, pred_array","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:29.784486Z","iopub.execute_input":"2022-11-16T21:59:29.785119Z","iopub.status.idle":"2022-11-16T21:59:29.798319Z","shell.execute_reply.started":"2022-11-16T21:59:29.785076Z","shell.execute_reply":"2022-11-16T21:59:29.797383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training a model and saving its statistics\ndef doProcess(modelsize, NULL):\n    # Prepare the data and the model\n    model, modelName, optimizer, trainloader, validationloader, testloader = prepareDataAndModel(modelsize, NULL)\n    # Train model\n    print('TRAINING AND SAVING MODEL: '+modelName)\n    model, best_result, statistics = train(model, optimizer, trainloader, validationloader)\n    \n    # Save training statistics\n    saveTrainPlots(best_result, statistics, modelName)\n    \n    # Run test\n    truth_array, pred_array = test(model, testloader)\n    \n    # Print and save test statistics\n    printAccuracy(truth_array, pred_array)\n    saveConfMtx(truth_array, pred_array, modelName, NULL)\n    \n    # Save the weights of the best model\n    torch.save(model.state_dict(), './'+modelName+'.pth')\n    print('---------------------------------------------------')","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:29.826979Z","iopub.execute_input":"2022-11-16T21:59:29.827600Z","iopub.status.idle":"2022-11-16T21:59:29.838080Z","shell.execute_reply.started":"2022-11-16T21:59:29.827565Z","shell.execute_reply":"2022-11-16T21:59:29.836970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the whole process on different configurations\ndoProcess(modelsize='small', NULL=False)\ndoProcess(modelsize='large', NULL=False)\ndoProcess(modelsize='small', NULL=True)\ndoProcess(modelsize='large', NULL=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T21:59:29.839708Z","iopub.execute_input":"2022-11-16T21:59:29.840446Z","iopub.status.idle":"2022-11-16T22:03:36.073112Z","shell.execute_reply.started":"2022-11-16T21:59:29.840364Z","shell.execute_reply":"2022-11-16T22:03:36.071389Z"},"trusted":true},"execution_count":null,"outputs":[]}]}